"""
Dirb Scanner Wrapper
====================

Web content scanner.
"""

import re
from typing import Dict, List, Any, Tuple, Optional

from ..base import ToolWrapper


class DirbScanner(ToolWrapper):
    TOOL_NAME = "Dirb"
    BINARY_NAME = "dirb"
    INSTALL_HINT = "Install with: apt install dirb"
    
    def build_command(
        self,
        target: str,
        wordlist: str = "/usr/share/dirb/wordlists/common.txt",
        extensions: Optional[str] = None,
        agent: Optional[str] = None,
        cookie: Optional[str] = None,
        username: Optional[str] = None,
        password: Optional[str] = None,
        not_recursive: bool = False,
        not_stop: bool = True,
        case_insensitive: bool = False,
        **kwargs
    ) -> List[str]:
        cmd = [self.BINARY_NAME, target, wordlist]
        
        if extensions:
            cmd.extend(["-X", extensions])
        
        if agent:
            cmd.extend(["-a", agent])
        
        if cookie:
            cmd.extend(["-c", cookie])
        
        if username and password:
            cmd.extend(["-u", f"{username}:{password}"])
        
        if not_recursive:
            cmd.append("-r")
        
        if not_stop:
            cmd.append("-S")
        
        if case_insensitive:
            cmd.append("-i")
        
        output_file = self.output_dir / f"dirb_{target.replace('://', '_').replace('/', '_')}.txt"
        cmd.extend(["-o", str(output_file)])
        
        return cmd
    
    def parse_output(self, output: str, error: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        findings = []
        raw_data = {"urls": [], "directories": []}
        
        # Parse found URLs
        url_pattern = r"\+\s+(https?://\S+)\s+\(CODE:(\d+)\|SIZE:(\d+)\)"
        for match in re.finditer(url_pattern, output):
            url_data = {
                "url": match.group(1),
                "status": int(match.group(2)),
                "size": int(match.group(3))
            }
            raw_data["urls"].append(url_data)
            
            findings.append(self._create_finding(
                title=f"Found: {url_data['url']}",
                severity="info",
                description=f"Status: {url_data['status']}, Size: {url_data['size']}",
                url=url_data["url"]
            ))
        
        # Parse directories
        dir_pattern = r"==> DIRECTORY:\s+(\S+)"
        for match in re.finditer(dir_pattern, output):
            raw_data["directories"].append(match.group(1))
        
        return findings, raw_data
