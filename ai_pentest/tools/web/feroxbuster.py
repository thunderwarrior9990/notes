"""
Feroxbuster Scanner Wrapper
===========================

Fast, recursive content discovery tool.
"""

import json
import re
from typing import Dict, List, Any, Tuple, Optional

from ..base import ToolWrapper


class FeroxbusterScanner(ToolWrapper):
    """
    Feroxbuster - Recursive content discovery
    
    Features:
    - Recursive scanning
    - Automatic calibration
    - Response filtering
    - Parallel processing
    """
    
    TOOL_NAME = "Feroxbuster"
    BINARY_NAME = "feroxbuster"
    INSTALL_HINT = "Install with: apt install feroxbuster / cargo install feroxbuster"
    
    def build_command(
        self,
        target: str,
        wordlist: str = "/usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt",
        extensions: Optional[List[str]] = None,
        threads: int = 50,
        depth: int = 4,
        timeout: int = 7,
        status_codes: Optional[List[int]] = None,
        filter_status: Optional[List[int]] = None,
        filter_size: Optional[List[int]] = None,
        auto_tune: bool = True,
        no_recursion: bool = False,
        extract_links: bool = True,
        **kwargs
    ) -> List[str]:
        cmd = [self.BINARY_NAME]
        
        cmd.extend(["-u", target])
        cmd.extend(["-w", wordlist])
        cmd.extend(["-t", str(threads)])
        cmd.extend(["-d", str(depth)])
        cmd.extend(["--timeout", str(timeout)])
        
        if extensions:
            cmd.extend(["-x", ",".join(extensions)])
        
        if status_codes:
            cmd.extend(["-s", ",".join(map(str, status_codes))])
        
        if filter_status:
            for code in filter_status:
                cmd.extend(["-C", str(code)])
        
        if filter_size:
            for size in filter_size:
                cmd.extend(["-S", str(size)])
        
        if auto_tune:
            cmd.append("--auto-tune")
        
        if no_recursion:
            cmd.append("-n")
        
        if extract_links:
            cmd.append("-e")
        
        output_file = self.output_dir / f"feroxbuster_{target.replace('://', '_').replace('/', '_')}.json"
        cmd.extend(["--json", "-o", str(output_file)])
        
        return cmd
    
    def parse_output(self, output: str, error: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        findings = []
        raw_data = {"urls": [], "redirects": [], "errors": []}
        
        # Try JSON output
        json_files = list(self.output_dir.glob("feroxbuster_*.json"))
        if json_files:
            try:
                with open(json_files[-1]) as f:
                    for line in f:
                        try:
                            entry = json.loads(line.strip())
                            if entry.get("type") == "response":
                                url_data = {
                                    "url": entry.get("url", ""),
                                    "status": entry.get("status", 0),
                                    "content_length": entry.get("content_length", 0),
                                    "word_count": entry.get("word_count", 0),
                                    "line_count": entry.get("line_count", 0)
                                }
                                raw_data["urls"].append(url_data)
                        except json.JSONDecodeError:
                            continue
            except Exception:
                pass
        
        # Create findings
        for url_data in raw_data["urls"]:
            severity = "info"
            url_lower = url_data["url"].lower()
            
            if any(x in url_lower for x in ["admin", "backup", "config", ".git", ".env", "upload"]):
                severity = "medium"
            elif any(x in url_lower for x in ["login", "api", "internal"]):
                severity = "low"
            
            findings.append(self._create_finding(
                title=f"Found: {url_data['url']}",
                severity=severity,
                description=f"Status: {url_data['status']}, Size: {url_data['content_length']}",
                url=url_data["url"],
                status_code=url_data["status"]
            ))
        
        return findings, raw_data
