"""
ParamSpider Scanner Wrapper
===========================

Parameter extraction from web archives.
"""

import re
from typing import Dict, List, Any, Tuple, Optional

from ..base import ToolWrapper


class ParamspiderScanner(ToolWrapper):
    """
    ParamSpider - URL Parameter Mining
    
    Features:
    - Web archive mining
    - Parameter extraction
    - URL pattern discovery
    """
    
    TOOL_NAME = "ParamSpider"
    BINARY_NAME = "paramspider"
    INSTALL_HINT = "Install with: pip install paramspider"
    
    def build_command(
        self,
        target: str,
        exclude: Optional[str] = None,
        level: str = "high",
        quiet: bool = False,
        **kwargs
    ) -> List[str]:
        cmd = [self.BINARY_NAME]
        
        cmd.extend(["-d", target])
        cmd.extend(["--level", level])
        
        if exclude:
            cmd.extend(["--exclude", exclude])
        
        if quiet:
            cmd.append("--quiet")
        
        output_file = self.output_dir / f"paramspider_{target.replace('.', '_')}.txt"
        cmd.extend(["-o", str(output_file)])
        
        return cmd
    
    def parse_output(self, output: str, error: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        findings = []
        raw_data = {"urls": [], "parameters": set()}
        
        output_files = list(self.output_dir.glob("paramspider_*.txt"))
        if output_files:
            try:
                with open(output_files[-1]) as f:
                    for line in f:
                        url = line.strip()
                        if url:
                            raw_data["urls"].append(url)
                            
                            # Extract parameters
                            if "?" in url:
                                params_part = url.split("?")[1]
                                for param in params_part.split("&"):
                                    param_name = param.split("=")[0]
                                    raw_data["parameters"].add(param_name)
            except Exception:
                pass
        
        raw_data["parameters"] = list(raw_data["parameters"])
        
        if raw_data["urls"]:
            findings.append(self._create_finding(
                title=f"Found {len(raw_data['urls'])} URLs with Parameters",
                severity="info",
                description=f"Unique parameters: {', '.join(list(raw_data['parameters'])[:10])}",
                url_count=len(raw_data["urls"])
            ))
        
        return findings, raw_data
