"""
AI Brain
=========

The intelligent decision-making core that analyzes tool outputs
and determines the next steps in the penetration test.

Supports multiple agent personas for specialized security testing.
"""

import json
from typing import Dict, List, Optional, Any, Tuple, TYPE_CHECKING
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

from rich.console import Console

from ..ai.cursor_client import CursorAIClient
from .attack_surface import (
    AttackSurface, Asset, Service, Vulnerability, 
    Technology, Credential, WebEndpoint,
    AssetType, ServiceType, VulnSeverity, VulnStatus
)

if TYPE_CHECKING:
    from ..agents.personas import AgentPersona


console = Console()


class DecisionType(Enum):
    """Types of decisions the AI can make"""
    RUN_TOOL = "run_tool"
    ANALYZE_DEEPER = "analyze_deeper"
    EXPLOIT = "exploit"
    PIVOT = "pivot"
    SKIP = "skip"
    REPORT = "report"
    MANUAL_REVIEW = "manual_review"


@dataclass
class AIDecision:
    """A decision made by the AI brain"""
    decision_type: DecisionType
    tool: str = ""
    target: str = ""
    parameters: Dict[str, Any] = field(default_factory=dict)
    reasoning: str = ""
    priority: int = 5  # 1-10, 10 being highest
    confidence: float = 0.8  # 0-1
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "decision_type": self.decision_type.value,
            "tool": self.tool,
            "target": self.target,
            "parameters": self.parameters,
            "reasoning": self.reasoning,
            "priority": self.priority,
            "confidence": self.confidence
        }


@dataclass
class ToolAnalysis:
    """AI analysis of a tool's output"""
    tool_name: str
    summary: str
    key_findings: List[Dict[str, Any]]
    new_targets: List[str]
    new_vulnerabilities: List[Dict[str, Any]]
    recommended_next_tools: List[str]
    risk_assessment: str
    notes: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "tool_name": self.tool_name,
            "summary": self.summary,
            "key_findings": self.key_findings,
            "new_targets": self.new_targets,
            "new_vulnerabilities": self.new_vulnerabilities,
            "recommended_next_tools": self.recommended_next_tools,
            "risk_assessment": self.risk_assessment,
            "notes": self.notes
        }


class AIBrain:
    """
    AI Brain - The intelligent decision-making core
    
    Responsibilities:
    - Analyze tool outputs and extract insights
    - Make decisions about next steps
    - Prioritize targets and vulnerabilities
    - Suggest exploitation approaches
    - Maintain context across the pentest
    
    Supports multiple agent personas for specialized behavior.
    """
    
    # Default system prompts (can be overridden by agent persona)
    TOOL_ANALYSIS_PROMPT = """You are an expert penetration tester analyzing tool output. 
Your task is to extract actionable intelligence from the results.

Analyze the tool output and provide:
1. A brief summary of what was found
2. Key security findings (vulnerabilities, misconfigurations, sensitive data)
3. New targets discovered (IPs, domains, services, endpoints)
4. Specific vulnerabilities to investigate further
5. Recommended next tools to run based on findings
6. Risk assessment (critical, high, medium, low)

Be precise and actionable. Focus on security-relevant information.
Output your analysis in JSON format with these keys:
- summary: string
- key_findings: array of {finding, severity, evidence}
- new_targets: array of strings
- new_vulnerabilities: array of {type, target, description, severity}
- recommended_next_tools: array of strings
- risk_assessment: string
- notes: string"""

    DECISION_PROMPT = """You are an expert penetration tester making strategic decisions.
Based on the current attack surface and recent findings, decide the next steps.

Consider:
1. What high-value targets have been identified?
2. What vulnerabilities are most critical/exploitable?
3. What areas haven't been explored yet?
4. What credentials or access do we have?
5. What's the most efficient path to demonstrate impact?

Provide your decision in JSON format:
{
    "decisions": [
        {
            "action": "run_tool|analyze_deeper|exploit|pivot|skip|report|manual_review",
            "tool": "tool_name if applicable",
            "target": "target if applicable",
            "parameters": {},
            "reasoning": "why this decision",
            "priority": 1-10,
            "confidence": 0.0-1.0
        }
    ],
    "overall_assessment": "summary of current state",
    "recommended_focus": "what to focus on next"
}"""

    EXPLOITATION_PROMPT = """You are an expert penetration tester advising on exploitation.
Based on the vulnerability details, provide exploitation guidance.

For the given vulnerability:
1. Confirm if it's exploitable
2. Suggest exploitation approach
3. Recommend tools or techniques
4. Outline proof of concept steps
5. Warn about potential risks/detection

IMPORTANT: This is for authorized security testing only.
Ensure the approach is safe and within scope."""

    def __init__(
        self, 
        api_key: Optional[str] = None,
        agent: Optional[str] = None,
        agent_persona: Optional["AgentPersona"] = None
    ):
        """
        Initialize the AI Brain.
        
        Args:
            api_key: API key for AI services
            agent: Agent name to use (e.g., "red_team", "bug_bounty")
            agent_persona: Direct AgentPersona object to use
        """
        self.ai_client: Optional[CursorAIClient] = None
        self.api_key = api_key
        self.analysis_history: List[ToolAnalysis] = []
        self.decision_history: List[AIDecision] = []
        self.context_memory: List[Dict[str, Any]] = []
        self._initialized = False
        
        # Agent persona support
        self.agent_persona: Optional["AgentPersona"] = None
        self._agent_name = agent
        
        if agent_persona:
            self.agent_persona = agent_persona
        elif agent:
            self._load_agent(agent)
    
    def _load_agent(self, agent_name: str) -> None:
        """Load an agent persona by name"""
        try:
            from ..agents import get_agent
            self.agent_persona = get_agent(agent_name)
            if self.agent_persona:
                console.print(f"[cyan]ðŸ¤– Agent loaded: {self.agent_persona.name}[/cyan]")
            else:
                console.print(f"[yellow]Agent '{agent_name}' not found, using default[/yellow]")
        except ImportError:
            console.print("[yellow]Agent module not available[/yellow]")
    
    def set_agent(self, agent: str) -> None:
        """Set the agent persona by name"""
        self._load_agent(agent)
    
    def set_agent_persona(self, persona: "AgentPersona") -> None:
        """Set the agent persona directly"""
        self.agent_persona = persona
        console.print(f"[cyan]ðŸ¤– Agent set: {persona.name}[/cyan]")
    
    def get_system_prompt(self, prompt_type: str = "analysis") -> str:
        """Get the system prompt, using agent persona if available"""
        if self.agent_persona:
            # Use agent's system prompt as base
            base_prompt = self.agent_persona.system_prompt
            
            # Add specific instructions based on prompt type
            if prompt_type == "analysis":
                return base_prompt + "\n\n" + self.TOOL_ANALYSIS_PROMPT
            elif prompt_type == "decision":
                return base_prompt + "\n\n" + self.DECISION_PROMPT
            elif prompt_type == "exploitation":
                return base_prompt + "\n\n" + self.EXPLOITATION_PROMPT
            else:
                return base_prompt
        else:
            # Use default prompts
            prompts = {
                "analysis": self.TOOL_ANALYSIS_PROMPT,
                "decision": self.DECISION_PROMPT,
                "exploitation": self.EXPLOITATION_PROMPT
            }
            return prompts.get(prompt_type, self.TOOL_ANALYSIS_PROMPT)
    
    def get_recommended_tools(self) -> List[str]:
        """Get recommended tools from current agent persona"""
        if self.agent_persona:
            return self.agent_persona.recommended_tools
        return []
    
    async def initialize(self) -> None:
        """Initialize the AI client"""
        if not self._initialized:
            self.ai_client = CursorAIClient(api_key=self.api_key)
            await self.ai_client._init_client()
            self._initialized = True
    
    async def close(self) -> None:
        """Close the AI client"""
        if self.ai_client:
            await self.ai_client.close()
            self._initialized = False
    
    async def analyze_tool_output(
        self,
        tool_name: str,
        target: str,
        output: str,
        findings: List[Dict[str, Any]],
        attack_surface: AttackSurface
    ) -> ToolAnalysis:
        """
        Analyze the output of a security tool
        
        Args:
            tool_name: Name of the tool
            target: Target that was scanned
            output: Raw output from the tool
            findings: Parsed findings from the tool
            attack_surface: Current attack surface
            
        Returns:
            ToolAnalysis with extracted intelligence
        """
        await self.initialize()
        
        console.print(f"[cyan]ðŸ§  AI analyzing {tool_name} results...[/cyan]")
        
        # Prepare context for AI
        context = {
            "tool": tool_name,
            "target": target,
            "findings_count": len(findings),
            "findings_sample": findings[:10],  # First 10 findings
            "output_sample": output[:5000] if output else "",  # First 5000 chars
            "current_assets": len(attack_surface.assets),
            "known_vulnerabilities": len(attack_surface.all_vulnerabilities)
        }
        
        try:
            response = await self.ai_client.analyze(
                prompt=f"""Analyze this {tool_name} scan output for target: {target}

Tool Output (sample):
```
{output[:3000] if output else "No raw output available"}
```

Parsed Findings:
```json
{json.dumps(findings[:10], indent=2)}
```

Current attack surface has {len(attack_surface.assets)} assets and {len(attack_surface.all_vulnerabilities)} known vulnerabilities.

Provide your analysis in the specified JSON format.""",
                system_prompt=self.get_system_prompt("analysis")
            )
            
            # Parse AI response
            analysis = self._parse_tool_analysis(tool_name, response.content)
            
        except Exception as e:
            console.print(f"[yellow]AI analysis failed: {e}, using fallback[/yellow]")
            analysis = self._fallback_analysis(tool_name, findings)
        
        self.analysis_history.append(analysis)
        self._update_context(tool_name, analysis)
        
        return analysis
    
    def _parse_tool_analysis(self, tool_name: str, response: str) -> ToolAnalysis:
        """Parse AI response into ToolAnalysis"""
        try:
            # Try to extract JSON from response
            import re
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                data = json.loads(json_match.group())
                return ToolAnalysis(
                    tool_name=tool_name,
                    summary=data.get("summary", ""),
                    key_findings=data.get("key_findings", []),
                    new_targets=data.get("new_targets", []),
                    new_vulnerabilities=data.get("new_vulnerabilities", []),
                    recommended_next_tools=data.get("recommended_next_tools", []),
                    risk_assessment=data.get("risk_assessment", "unknown"),
                    notes=data.get("notes", "")
                )
        except json.JSONDecodeError:
            pass
        
        # Fallback: use raw response as summary
        return ToolAnalysis(
            tool_name=tool_name,
            summary=response[:500],
            key_findings=[],
            new_targets=[],
            new_vulnerabilities=[],
            recommended_next_tools=[],
            risk_assessment="unknown",
            notes=response
        )
    
    def _fallback_analysis(self, tool_name: str, findings: List[Dict[str, Any]]) -> ToolAnalysis:
        """Fallback analysis when AI is unavailable"""
        key_findings = []
        new_vulns = []
        
        for f in findings:
            severity = f.get("severity", "info")
            if severity in ["critical", "high"]:
                key_findings.append({
                    "finding": f.get("title", "Unknown"),
                    "severity": severity,
                    "evidence": f.get("evidence", "")[:200]
                })
                
                new_vulns.append({
                    "type": f.get("title", "Unknown"),
                    "target": f.get("url", f.get("target", "")),
                    "description": f.get("description", ""),
                    "severity": severity
                })
        
        return ToolAnalysis(
            tool_name=tool_name,
            summary=f"Analyzed {len(findings)} findings from {tool_name}",
            key_findings=key_findings[:5],
            new_targets=[],
            new_vulnerabilities=new_vulns[:5],
            recommended_next_tools=[],
            risk_assessment="high" if key_findings else "low",
            notes="Fallback analysis - AI unavailable"
        )
    
    async def decide_next_steps(
        self,
        attack_surface: AttackSurface,
        current_phase: str,
        recent_analysis: Optional[ToolAnalysis] = None,
        available_tools: Optional[List[str]] = None
    ) -> List[AIDecision]:
        """
        Decide what to do next based on current state
        
        Args:
            attack_surface: Current attack surface
            current_phase: Current phase of the pentest
            recent_analysis: Most recent tool analysis
            available_tools: Tools available to run
            
        Returns:
            List of AIDecision objects prioritized by importance
        """
        await self.initialize()
        
        console.print(f"[cyan]ðŸ§  AI deciding next steps for {current_phase} phase...[/cyan]")
        
        # Prepare context
        context = {
            "phase": current_phase,
            "attack_surface_summary": attack_surface.get_summary(),
            "high_value_targets": [a.to_dict() for a in attack_surface.get_high_value_targets()[:5]],
            "recent_findings": recent_analysis.to_dict() if recent_analysis else None,
            "available_tools": available_tools or self._get_phase_tools(current_phase),
            "unexplored_assets": self._find_unexplored_assets(attack_surface),
            "attack_paths": attack_surface.get_attack_paths()[:5]
        }
        
        # Add agent-specific context
        agent_info = ""
        if self.agent_persona:
            agent_info = f"\n\nAgent: {self.agent_persona.name}\nFocus Areas: {', '.join(self.agent_persona.focus_areas)}"
        
        try:
            response = await self.ai_client.analyze(
                prompt=f"""Current pentest state:
Phase: {current_phase}{agent_info}

Attack Surface Summary:
{json.dumps(context['attack_surface_summary'], indent=2)}

High Value Targets:
{json.dumps(context['high_value_targets'], indent=2)}

Recent Analysis:
{json.dumps(context['recent_findings'], indent=2) if context['recent_findings'] else 'None'}

Available Tools:
{json.dumps(context['available_tools'], indent=2)}

Unexplored Areas:
{json.dumps(context['unexplored_assets'], indent=2)}

Known Attack Paths:
{json.dumps(context['attack_paths'], indent=2)}

Based on this information, what should we do next? Provide 3-5 prioritized decisions.""",
                system_prompt=self.get_system_prompt("decision")
            )
            
            decisions = self._parse_decisions(response.content)
            
        except Exception as e:
            console.print(f"[yellow]AI decision failed: {e}, using heuristics[/yellow]")
            decisions = self._heuristic_decisions(attack_surface, current_phase)
        
        self.decision_history.extend(decisions)
        
        return decisions
    
    def _parse_decisions(self, response: str) -> List[AIDecision]:
        """Parse AI response into decisions"""
        decisions = []
        
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                data = json.loads(json_match.group())
                
                for d in data.get("decisions", []):
                    decision_type = {
                        "run_tool": DecisionType.RUN_TOOL,
                        "analyze_deeper": DecisionType.ANALYZE_DEEPER,
                        "exploit": DecisionType.EXPLOIT,
                        "pivot": DecisionType.PIVOT,
                        "skip": DecisionType.SKIP,
                        "report": DecisionType.REPORT,
                        "manual_review": DecisionType.MANUAL_REVIEW
                    }.get(d.get("action", ""), DecisionType.SKIP)
                    
                    decisions.append(AIDecision(
                        decision_type=decision_type,
                        tool=d.get("tool", ""),
                        target=d.get("target", ""),
                        parameters=d.get("parameters", {}),
                        reasoning=d.get("reasoning", ""),
                        priority=d.get("priority", 5),
                        confidence=d.get("confidence", 0.7)
                    ))
        except json.JSONDecodeError:
            pass
        
        if not decisions:
            decisions = [AIDecision(
                decision_type=DecisionType.MANUAL_REVIEW,
                reasoning="Could not parse AI response, manual review recommended",
                priority=5,
                confidence=0.5
            )]
        
        # Sort by priority
        decisions.sort(key=lambda d: d.priority, reverse=True)
        
        return decisions
    
    def _heuristic_decisions(
        self,
        attack_surface: AttackSurface,
        current_phase: str
    ) -> List[AIDecision]:
        """Make decisions using heuristics when AI is unavailable"""
        decisions = []
        
        if current_phase == "reconnaissance":
            # Basic recon decisions
            if len(attack_surface.subdomains) < 10:
                decisions.append(AIDecision(
                    decision_type=DecisionType.RUN_TOOL,
                    tool="SubfinderEnumerator",
                    target=attack_surface.primary_target,
                    reasoning="Need more subdomain discovery",
                    priority=8
                ))
            
            for asset in attack_surface.assets.values():
                if not asset.services:
                    decisions.append(AIDecision(
                        decision_type=DecisionType.RUN_TOOL,
                        tool="NmapScanner",
                        target=asset.name,
                        reasoning=f"No port scan done for {asset.name}",
                        priority=7
                    ))
        
        elif current_phase == "enumeration":
            for asset in attack_surface.assets.values():
                if asset.has_web_service() and not asset.web_endpoints:
                    decisions.append(AIDecision(
                        decision_type=DecisionType.RUN_TOOL,
                        tool="GobusterScanner",
                        target=asset.name,
                        reasoning=f"Web enumeration needed for {asset.name}",
                        priority=7
                    ))
        
        elif current_phase == "vulnerability":
            # Prioritize assets with services
            for asset in attack_surface.get_high_value_targets()[:3]:
                if not asset.vulnerabilities:
                    decisions.append(AIDecision(
                        decision_type=DecisionType.RUN_TOOL,
                        tool="NucleiScanner",
                        target=asset.name,
                        reasoning=f"Vulnerability scan needed for high-value target",
                        priority=9
                    ))
        
        return decisions
    
    async def analyze_vulnerability(
        self,
        vulnerability: Vulnerability,
        attack_surface: AttackSurface
    ) -> Dict[str, Any]:
        """
        Deep analysis of a specific vulnerability
        
        Returns exploitation guidance and risk assessment
        """
        await self.initialize()
        
        context = {
            "vulnerability": vulnerability.to_dict(),
            "affected_asset": attack_surface.get_asset(vulnerability.affected_asset).to_dict() if vulnerability.affected_asset in attack_surface.assets else None,
            "related_vulns": [v.to_dict() for v in attack_surface.all_vulnerabilities if v.cve_id == vulnerability.cve_id and v.id != vulnerability.id]
        }
        
        try:
            response = await self.ai_client.analyze(
                prompt=f"""Analyze this vulnerability for exploitation potential:

Vulnerability:
{json.dumps(context['vulnerability'], indent=2)}

Affected Asset:
{json.dumps(context['affected_asset'], indent=2) if context['affected_asset'] else 'Unknown'}

Provide:
1. Exploitability assessment (1-10)
2. Recommended exploitation approach
3. Required tools
4. Proof of concept outline
5. Detection risk
6. Recommended mitigations""",
                system_prompt=self.EXPLOITATION_PROMPT
            )
            
            return {
                "vulnerability_id": vulnerability.id,
                "analysis": response.content,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "vulnerability_id": vulnerability.id,
                "analysis": f"Analysis failed: {e}",
                "timestamp": datetime.now().isoformat()
            }
    
    async def generate_attack_plan(
        self,
        attack_surface: AttackSurface
    ) -> Dict[str, Any]:
        """Generate a comprehensive attack plan based on current findings"""
        await self.initialize()
        
        summary = attack_surface.get_summary()
        high_value = [a.to_dict() for a in attack_surface.get_high_value_targets()[:5]]
        critical_vulns = [v.to_dict() for v in attack_surface.get_critical_vulnerabilities()[:5]]
        attack_paths = attack_surface.get_attack_paths()[:5]
        
        try:
            response = await self.ai_client.analyze(
                prompt=f"""Based on the current attack surface, generate a prioritized attack plan.

Summary:
{json.dumps(summary, indent=2)}

High-Value Targets:
{json.dumps(high_value, indent=2)}

Critical Vulnerabilities:
{json.dumps(critical_vulns, indent=2)}

Known Attack Paths:
{json.dumps(attack_paths, indent=2)}

Create a step-by-step attack plan that:
1. Prioritizes the most impactful vulnerabilities
2. Chains attacks for maximum effect
3. Considers detection risk
4. Outlines contingency approaches
5. Estimates success probability

Format as JSON with keys: phases, steps, risks, contingencies, success_estimate""",
                system_prompt="""You are an expert penetration tester creating an attack plan.
Focus on demonstrating real security impact while staying within scope.
All activities must be authorized and documented."""
            )
            
            return {
                "attack_plan": response.content,
                "generated_at": datetime.now().isoformat(),
                "based_on": summary
            }
            
        except Exception as e:
            return {
                "attack_plan": f"Plan generation failed: {e}",
                "generated_at": datetime.now().isoformat()
            }
    
    def _get_phase_tools(self, phase: str) -> List[str]:
        """Get recommended tools for a phase"""
        phase_tools = {
            "reconnaissance": [
                "NmapScanner", "SubfinderEnumerator", "AmassEnumerator",
                "TheHarvesterScanner", "DnsenumScanner"
            ],
            "enumeration": [
                "GobusterScanner", "FeroxbusterScanner", "HttpxScanner",
                "Enum4linuxScanner", "WpscanScanner"
            ],
            "vulnerability": [
                "NucleiScanner", "NiktoScanner", "SqlmapScanner",
                "DalfoxScanner", "Wafw00fScanner"
            ],
            "exploitation": [
                "HydraAttacker", "CrackmapexecScanner", "NetexecScanner",
                "EvilWinrmShell"
            ],
            "post_exploitation": [
                "Volatility3Analyzer", "StringsExtractor"
            ]
        }
        return phase_tools.get(phase, [])
    
    def _find_unexplored_assets(self, attack_surface: AttackSurface) -> List[Dict[str, Any]]:
        """Find assets that haven't been fully explored"""
        unexplored = []
        
        for asset in attack_surface.assets.values():
            reasons = []
            
            if not asset.services:
                reasons.append("no_port_scan")
            if asset.has_web_service() and not asset.web_endpoints:
                reasons.append("no_web_enum")
            if not asset.vulnerabilities:
                reasons.append("no_vuln_scan")
            
            if reasons:
                unexplored.append({
                    "asset": asset.name,
                    "type": asset.asset_type.value,
                    "missing": reasons
                })
        
        return unexplored[:10]
    
    def _update_context(self, tool: str, analysis: ToolAnalysis) -> None:
        """Update context memory with new analysis"""
        self.context_memory.append({
            "tool": tool,
            "timestamp": datetime.now().isoformat(),
            "summary": analysis.summary,
            "findings_count": len(analysis.key_findings),
            "risk": analysis.risk_assessment
        })
        
        # Keep last 50 entries
        if len(self.context_memory) > 50:
            self.context_memory = self.context_memory[-50:]
    
    def get_context_summary(self) -> str:
        """Get a summary of recent context for AI prompts"""
        if not self.context_memory:
            return "No previous context"
        
        recent = self.context_memory[-5:]
        summaries = [
            f"- {c['tool']}: {c['summary'][:100]}... (Risk: {c['risk']})"
            for c in recent
        ]
        return "\n".join(summaries)
